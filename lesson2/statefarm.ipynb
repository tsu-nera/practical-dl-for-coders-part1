{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Vgg16 model with Keras\n",
    "\n",
    "[State Farm Distracted Driver Detection | Kaggle](https://www.kaggle.com/c/state-farm-distracted-driver-detection/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "#path = \"data/state/\"\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../utils'))\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR = \"/home/ubuntu/datasets/state-farm-distracted-driver-detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir ../sample\n",
    "%mkdir ../sample/train\n",
    "%mkdir ../sample/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create c0 .. c9 in train/valid directory\n",
    "for d in glob('c?'):\n",
    "    os.mkdir('../sample/train/'+d)\n",
    "    os.mkdir('../sample/valid/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy c?/*.jpg to sample/train/c?/*.jpg\n",
    "g = glob('c?/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(1500): copyfile(shuf[i], '../sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ../valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('c?/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(1000): copyfile(shuf[i], '../sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data with pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb\n",
    "\n",
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))\n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def finetune(model, num_classes):\n",
    "    # remove last layer\n",
    "    model.pop()\n",
    "    # set all layers untrainable.\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    # add new layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_batches(path, dirname, gen=image.ImageDataGenerator(), shuffle=True,\n",
    "                batch_size=64, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224),\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get pre-trained weight from fast.ai server http://www.platform.ai/models/\n",
    "\n",
    "```wget http://www.platform.ai/models/vgg16.h5```\n",
    "\n",
    "You can also download [here](https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch=1):\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.N, nb_epoch=nb_epoch, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_5 (Lambda)                (None, 3, 224, 224)   0           lambda_input_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_53 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_53 (Convolution2D) (None, 64, 224, 224)  1792        zeropadding2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_54 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_53[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_54 (Convolution2D) (None, 64, 224, 224)  36928       zeropadding2d_54[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_21 (MaxPooling2D)   (None, 64, 112, 112)  0           convolution2d_54[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_55 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_21[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_55 (Convolution2D) (None, 128, 112, 112) 73856       zeropadding2d_55[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_56 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_55[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_56 (Convolution2D) (None, 128, 112, 112) 147584      zeropadding2d_56[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_22 (MaxPooling2D)   (None, 128, 56, 56)   0           convolution2d_56[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_57 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_22[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_57 (Convolution2D) (None, 256, 56, 56)   295168      zeropadding2d_57[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_58 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_57[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_58 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_59 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_59 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_59[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_23 (MaxPooling2D)   (None, 256, 28, 28)   0           convolution2d_59[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_60 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_60 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_60[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_61 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_60[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_61 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_61[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_62 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_61[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_62 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_24 (MaxPooling2D)   (None, 512, 14, 14)   0           convolution2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_63 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_24[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_63 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_64 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_64 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_64[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_65 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_64[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_65 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_65[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_25 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_65[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 25088)         0           maxpooling2d_25[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 4096)          102764544   flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 4096)          0           dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 4096)          16781312    dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 4096)          0           dense_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 10)            40970       dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 134301514\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG_16()\n",
    "\n",
    "# load pre-trained weights!!!\n",
    "model.load_weights('vgg16.h5')\n",
    "\n",
    "# remove last layer and add new layer\n",
    "# ftmodel = finetune(model,10)\n",
    "\n",
    "model.pop()\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "layers = model.layers\n",
    "opt = RMSprop(lr=0.1)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "for layer in layers[12:]: layer.trainable=True\n",
    "K.set_value(opt.lr, 0.001)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "# path = DATA_HOME_DIR\n",
    "path = \"/home/ubuntu/datasets/state-farm-distracted-driver-detection/sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path,'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path,'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train finetuned model(only last layer)\n",
    "no_of_epochs=1\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    ftmodel.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    ftmodel.save_weights(latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftmodel.load_weights(\"ft0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 166s - loss: 14.0808 - acc: 0.0993 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 166s - loss: 14.4740 - acc: 0.1020 - val_loss: 14.5869 - val_acc: 0.0950\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 165s - loss: 14.4740 - acc: 0.1020 - val_loss: 14.4902 - val_acc: 0.1010\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 166s - loss: 14.4740 - acc: 0.1020 - val_loss: 14.5708 - val_acc: 0.0960\n"
     ]
    }
   ],
   "source": [
    "fit_model(model, batches, val_batches, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"ftvgg_train12.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(DATA_HOME_DIR, 'test', batch_size=2*batch_size, class_mode=None)\n",
    "preds = model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(DATA_HOME_DIR+\"submission2.csv\")\n",
    "#classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "#preds = df[classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)\n",
    "preds = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_81601.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_14887.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_62885.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_45125.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_22633.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2    c3        c4        c5  \\\n",
       "0  img_81601.jpg  0.007778  0.007778  0.007778  0.93  0.007778  0.007778   \n",
       "1  img_14887.jpg  0.007778  0.007778  0.007778  0.93  0.007778  0.007778   \n",
       "2  img_62885.jpg  0.007778  0.007778  0.007778  0.93  0.007778  0.007778   \n",
       "3  img_45125.jpg  0.007778  0.007778  0.007778  0.93  0.007778  0.007778   \n",
       "4  img_22633.jpg  0.007778  0.007778  0.007778  0.93  0.007778  0.007778   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.007778  0.007778  \n",
       "2  0.007778  0.007778  0.007778  0.007778  \n",
       "3  0.007778  0.007778  0.007778  0.007778  \n",
       "4  0.007778  0.007778  0.007778  0.007778  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "submission = pd.DataFrame(preds, columns=classes)\n",
    "submission.insert(0, 'img', [a[8:] for a in test_batches.filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission3.csv' target='_blank'>submission3.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/lesson2/submission3.csv"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(\"submission3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
